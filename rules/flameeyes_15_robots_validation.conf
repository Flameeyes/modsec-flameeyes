# -*- apache -*-
# Copyright © 2010-2013 Diego Elio Pettenò <flameeyes@flameeyes.eu>
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
#
# Rules for validation of legit robots and crawlers (search engines
# and services).
#
# Most search engines and other services that make use of robots and
# crawlers provide a way to safely ensure that the request is really
# coming from them by using FcRDNS (Forward-confirmed Reverse
# DNS). This is done through the following steps:
#
#  - take the IP the request comes from, and do a reverse-DNS query
#    for it;
#  - compare the returned hostname against the valid hostname pattern
#    for the bot;
#  - confirm that the reverse DNS response is valid by ensuring that
#    the hostname resolution reports, at least once, the original IP
#    we started from.
#
# Thankfully, Apache already solves half the problem for us, if the
# following option is enabled:
#
#   HostnameLookups Double
#
# When this is enabled, the REMOTE_HOST variable will be set to the
# reverse DNS, but only if it's confirmed, otherwise it'll still
# report the IP address.
#
# The tests in this file make use of this feature, so if you don't
# want to do the double-resolution, you might want to remove it, or
# otherwise, add the directive as shown before.
#
# Note: if you still want to keep the same format in the log files,
# with IP rather than hostnames, you have to also change your
# CustomLog directive.
#
# As with the RBL checks, it is recommended to have a caching name
# server or NSCD service available to the server to reduce the latency
# on repeated requests.
#
# References:
#   https://blog.flameeyes.eu/2009/12/04/do-i-hate-bots-too-much
#   http://googlewebmastercentral.blogspot.com/2006/09/how-to-verify-googlebot.html

# For now ignore acapbot's claim of being googlebot; it's not, but it's
# used by Amazon Affiliate program for customised Ads banners page
# scraping.
SecRule REQUEST_HEADERS:User-Agent "@contains acapbot" \
	"id:431517,skip:1,phase:2"
	# Note that ID is out-of-order by need.

SecRule REQUEST_HEADERS:User-Agent "@contains googlebot" \
	"id:431500,t:lowercase,chain,deny,status:403,msg:'Fake Googlebot crawler.',phase:2"
SecRule REMOTE_HOST "!@endsWith .googlebot.com" "chain"
SecRule REQUEST_HEADERS:User-Agent "!^Googlebot-richsnippets"

SecRule REQUEST_HEADERS:User-Agent "@pm msnbot bingbot bingpreview" \
	"id:431501,t:lowercase,chain,deny,status:403,msg:'Fake msnbot/bingbot/bingpreview crawler.',phase:2"
SecRule REMOTE_HOST "!(msnbot-\d+-\d+-\d+-\d+\.search\.msn\.com|\.msn\.net)$"

SecRule REQUEST_HEADERS:User-Agent "@contains yahoo! slurp" \
	"id:431502,t:lowercase,chain,deny,status:403,msg:'Fake Yahoo! Slurp crawler.',phase:2"
SecRule REMOTE_HOST "!\.yahoo\.(?:com|net)$"

SecRule REQUEST_HEADERS:User-Agent "@contains yahoo pipes" \
	"id:431503,t:lowercase,chain,deny,status:403,msg:'Fake Yahoo Pipes crawler.',phase:2"
SecRule REMOTE_HOST "!\.yahoo\.(?:com|net)$"

SecRule REQUEST_HEADERS:User-Agent "@contains yeti/" \
	"id:431504,t:lowercase,chain,deny,status:403,msg:'Fake Yeti crawler.',phase:2"
SecRule REMOTE_HOST "!^crawl-\d+-\d+-\d+-\d+\.naver\.jp$"

SecRule REQUEST_HEADERS:User-Agent "@contains hailoobot" \
        "id:431505,t:lowercase,chain,deny,status:403,msg:'Fake Hailoobot crawler.',phase:2"
SecRule REMOTE_HOST "!@eq webcrawler.hailoo.com"

SecRule REQUEST_HEADERS:User-Agent "@contains technoratibot/" \
        "id:431506,t:lowercase,chain,deny,status:403,msg:'Fake Technoratibot crawler.',phase:2"
SecRule REMOTE_HOST "!@eq crawler.technorati.com"

SecRule REQUEST_HEADERS:User-Agent "@contains friendfeedbot/" \
        "id:431507,t:lowercase,chain,deny,status:403,msg:'Fake FriendFeed crawler.',phase:2"
SecRule REMOTE_HOST "!@endsWith .facebook.com"

# Yandex has a lot of different bots to the point that it's easier to just list
# them in a separate file. See http://yandex.com/bots and
# https://yandex.com/support/webmaster/robot-workings/check-yandex-robots.html
SecRule REQUEST_HEADERS:User-Agent "@pmfromfile flameeyes_yandex_bots.data" \
        "id:431508,t:lowercase,chain,deny,status:403,msg:'Fake Yandex crawler.',phase:2"
SecRule REMOTE_HOST "!\.yandex\.(?:ru|com|net)$"

SecRule REQUEST_HEADERS:User-Agent "@contains netvibes" \
        "id:431509,t:lowercase,chain,deny,status:403,msg:'Fake Netvibes crawler.',phase:2"
SecRule REMOTE_HOST "!@endsWith .netvibes.com"

SecRule REQUEST_HEADERS:User-Agent "@contains bloglines/" \
	"id:431510,t:lowercase,chain,deny,status:403,msg:'Fake Bloglines crawler.',phase:2"
SecRule REMOTE_HOST "@streq crawler.bloglines.com"

# ID 431511 was retired, don't reuse code.

SecRule REQUEST_HEADERS:User-Agent "@contains blogscope" \
	"id:431512,t:lowercase,chain,deny,status:403,msg:'Fake BlogScope crawler.',phase:2"
SecRule REMOTE_HOST "@endsWith .toronto.edu"

SecRule REQUEST_HEADERS:User-Agent "@contains newsgator" \
        "id:431513,t:lowercase,chain,deny,status:403,msg:'Fake NewsGatorOnline crawler.',phase:2"
SecRule REMOTE_HOST "@endsWith .newsgator.com"

SecRule REQUEST_HEADERS:User-Agent "@contains mediapartners-google" \
	"id:431514,t:lowercase,chain,deny,status:403,msg:'Fake AdSense crawler.',phase:2"
SecRule REMOTE_HOST "!@rx \.google(?:bot)?\.com$"

SecRule REQUEST_HEADERS:User-Agent "@contains archive.org_bot" \
	"id:431515,t:lowercase,chain,deny,status:403,msg:'Fake archive.org crawler.',phase:2"
SecRule REMOTE_HOST "!@endsWith .archive.org"

SecRule REQUEST_HEADERS:User-Agent "@contains adsbot-google" \
	"id:431516,t:lowercase,chain,deny,status:403,msg:'Fake AdWords crawler.',phase:2"
SecRule REMOTE_HOST "!@rx \.google(?:bot)?\.com$"

#### ID 431517 is present out of order.

# See www.baidu.com/search/spider_english.html for details on how this works
SecRule REQUEST_HEADERS:User-Agent "@contains baiduspider" \
	"id:431518,t:lowercase,chain,deny,status:403,msg:'Fake Baidu crawler.',phase:2"
SecRule REMOTE_HOST "!@rx \.crawl\.baidu\.(?:com|jp)$"

# See https://www.mojeek.com/bot.html
SecRule REQUEST_HEADERS:User-Agent "@contains mojeekbot" \
	"id:431519,t:lowercase,chain,deny,status:403,msg:'Fake Mojeek crawler.',phase:2"
SecRule REMOTE_HOST "!@endsWith .mojeek.com"

SecRule REQUEST_HEADERS:User-Agent "@contains linkedinbot" \
	"id:431520,t:lowercase,chain,deny,status:403,msg:'Fake LinkedInBot crawler.',phase:2"
SecRule REMOTE_HOST "!@endsWith .linkedin.com"

# Documented at http://www.apple.com/go/applebot
SecRule REQUEST_HEADERS:User-agent "@contains applebot" \
	"id:431521,t:lowercase,chain,deny,status:403,msg:'Fake Applebot crawler.',phase:2"
SecRule REMOTE_ADDR "@ipMatch 17.0.0.0/8"
