# -*- apache -*-
# Copyright © 2010-2012 Diego Elio Pettenò <flameeyes@flameeyes.eu>

# A number of spambots tries to mimic known good User-Agent values,
# harvested either on honeypot sites, or through statistics viewers
# such as awstats. Often enough, they get them slightly wrong,
# mangling a few key characters, try to identify them and reject them
# on that basis.
SecRule REQUEST_HEADERS:User-Agent "@beginsWith mozilla/4.0+" \
	"id:436001,phase:2,t:lowercase,msg:'Spaces converted to + symbols: %{REQUEST_HEADERS.User-Agent}',deny,status:403"
SecRule REQUEST_HEADERS:User-Agent "@contains (compatible- " \
	"id:436002,phase:2,t:lowercase,msg:'Semicolons replaced by dashes: %{REQUEST_HEADERS.User-Agent}',deny,status:403"
SecRule REQUEST_HEADERS:User-Agent "\([^\)]+$" \
	"id:436003,phase:2,msg:'Unterminated User-Agent string: %{REQUEST_HEADERS.User-Agent}',deny,status:403"
SecRule Request_HEADERS:User-Agent "\)\)$" \
	"id:436004,phase:2,msg:'Double-terminated User-Agent string: %{REQUEST_HEADERS.User-Agent}',deny,status:403"

# Yet another common mistake from false user-agents: they don't add
# the proper space after the first agent declaration (noticed with
# fake Opera strings, but it's a possible general mistake).
SecRule REQUEST_HEADERS:User-Agent "^[a-zA-Z]+/[0-9.]+\(" \
        "id:436010,phase:2,t:none,msg:'No space before parenthesis: %{REQUEST_HEADERS.User-Agent}',deny,status:403"

# MSIE reports a single .NET CLR token for each version of .NET that
# is installed, but only once per series.
#
# An exception seems to apply to .net clr 3.0 whereby many users seem
# to report both version 3.0.4506.2152 and 3.0.04504.30, in different
# orders; while it might be some malware's watermarking I've been
# unable to track it down for sure and it causes more trouble than it
# fixes.
SecRule REQUEST_HEADERS:User-Agent "(?:\.net clr 1\.0.*\.net clr 1\.0|\.net clr 1\.1.*\.net clr 1\.1|\.net clr 2\.0.*\.net clr 2\.0|\.net clr 3\.5.*\.net clr 3\.5|\.net clr 4\.0.*\.net clr 4\.0)" \
        "id:436020,phase:2,t:lowercase,msg:'Multiple .NET CLR tokens: %{REQUEST_HEADERS.User-Agent}',deny,status:403"

# No known implementation of .NET on Linux adds a ".NET CLR"
# specification to Firefox; so if you find any of that, simply kill
# them.
SecRule REQUEST_HEADERS:User-Agent ".* Linux .* Gecko/.*\.NET CLR" \
        "id:436030,phase:2,t:none,msg:'Fake browser; Firefox on Linux never reports .NET CLR: %{REQUEST_HEADERS.User-Agent}',deny,status:403"

# There are a few browsers that really doesn't exist anymore for real,
# but are still used by spammers; make sure to filter those as well.
SecRule REQUEST_HEADERS:User-Agent "@pmFromFile flameeyes_bad_browsers.data" \
	"id:436040,phase:2,t:lowercase,deny,status:403,msg:'Suspect browser %{REQUEST_HEADERS.User-Agent}'"

# Opera is one of the few browsers that doesn't declare itself as
# Mozilla/*; some spammers though insists on declaring themselves MSIE
# and Opera. And there are other fake Opera browser User-Agents
# around.
#
# Unfortunately, Opera Mini on some operating systems has a very bogus
# User-agent string, so don't report problems if the connection is
# declaring itself WAP.
SecRule REQUEST_HEADERS:User-Agent "^.* opera[ /][0-9]" \
        "id:436050,phase:2,t:lowercase,msg:'Fake Opera browser (not starting with Opera)',deny,status:403,chain"
SecRule &REQUEST_HEADERS:X-Wap-Profile "@eq 0"

# Mozilla/5.0 is legitimately declared by Gecko (Mozilla engine),
# WebKit (Safari, Chrome, ...) and MSIE 9.0, plus a bunch of crawlers.
#
# Anything else (MSIE < 9, Opera, ...) is a spammer or some other
# likely try at DDoSing, so reject them.
SecRule REQUEST_HEADERS:User-Agent "^mozilla/5\.0 " \
	"id:436060,phase:2,t:lowercase,chain,msg:'Unexpected Mozilla/5.0 browser %{REQUEST_HEADERS.User-Agent}.',deny,status:403"
SecRule REQUEST_HEADERS:User-Agent "! (?:gecko|msie 9\.)" "t:lowercase,chain"
SecRule IP:IS_ROBOT "!@eq 1"

# Futhermore, Mozilla/5.0 is generally used at the start of the
# User-Agent string, only a handful of crawlers don't do that, but
# ignore their existence (they should be fixed anyway); so if there is
# mozilla/5.0 but it's not at the start, kill the request.
SecRule REQUEST_HEADERS:User-Agent "^.+mozilla/5\.0" \
        "id:436070,phase:2,t:lowercase,msg:'Invalid Mozilla/5.0 browser %{REQUEST_HEADERS.User-Agent}.',deny,status:403"

###############################
# HEADER CHECKING STARTS HERE #
###############################

# Checking if the browser provides all HTTP/1.1-compliant headers is
# usually very helpful; unfortunately a number of transparent proxies
# seem to mangle this badly, causing false positives. If using a
# proxy, bypass this section.

SecRule &REQUEST_HEADERS:Via "@eq 1" \
        "id:436080,phase:2,skipAfter:FLAMEEYES_END_FAKE_BROWSERS_HEADERS,nolog"

# Not sending Accept header is a protocol violation in HTTP/1.1;
# browsers always send it, legit crawlers sometimes don't send it, but
# spammers masking as real browsers do often enough.
SecRule &REQUEST_HEADERS:Accept "@eq 0" \
        "id:436081,chain,phase:2,msg:'Missing Accept header when passing as a browser',deny,status:403"
SecRule REQUEST_HEADERS:User-Agent "@pm safari firefox msie opera" \
        "t:lowercase,chain"
# Android ICS up to 4.0.3 at least has a non-compliant browser, which
# does not send Accept headers at all. Ignore Android 4 requests for
# now until at least a fix comes up.
SecRule REQUEST_HEADERS:User-Agent "!android 4\.0" "t:lowercase"

# There is no requirement for other Accept-* headers to be present,
# but most browsers send it anyway, and we can use them to judge
# whether a browser is real or not.
SecRule &REQUEST_HEADERS:Accept-Encoding "@eq 0" \
        "id:436082,chain,phase:2,msg:'Missing Accept-Encoding header when passing as a browser',deny,status:403"
SecRule REQUEST_HEADERS:User-Agent "@pm msie safari opera" \
        "t:lowercase"

SecRule &REQUEST_HEADERS:Accept-Language "@eq 0" \
        "id:436083,chain,phase:2,msg:'Missing Accept-Language header when passing as a browser',deny,status:403"
SecRule REQUEST_HEADERS:User-Agent "@pm safari opera" \
        "t:lowercase,chain"
# Epiphany browser reports itself as Safari (and Chrome!) but has a
# much rougher HTTP implementation.  Similarly dwb.  GoogleBot reports
# itself as Mobile Safari, but uses a much reduced request
SecRule REQUEST_HEADERS:User-Agent "!@pm dwb epiphany googlebot" \
        "t:lowercase"

# The Shared Dictionary Compression for HTTP is a technique proposed
# by Google for compressing HTML output; there is no current
# implementation of it, as far as I can tell, but Chrome (and
# Chromium) still report supporting it, and they are the only ones as
# far as I know.
SecRule REQUEST_HEADERS:Accept-Encoding "@pm sdch" \
        "id:436084,chain,phase:2,msg:'Fake browser reports supporting sdch: %{REQUEST_HEADERS.User-Agent}',deny,status:403"
SecRule REQUEST_HEADERS:User-Agent "!@pm chrome crmo" "t:lowercase"

# For whatever reason Epiphany declares itself as Chrome, but does not
# support sdch, so check against that as well.
# Chrome Frame also would hit, but it doesn't add support for sdch
SecRule REQUEST_HEADERS:Accept-Encoding "!@pm sdch" \
        "id:436085,chain,phase:2,msg:'Fake Chrome not supporting sdch: %{REQUEST_HEADERS.User-Agent}',deny,status:403"
SecRule REQUEST_HEADERS:User-Agent "@pm chrome" "t:lowercase,chain"
SecRule REQUEST_HEADERS:User-Agent "! (?:epiphany/[0-9\.]+|chromeframe)" "t:lowercase"

# Sony PlayStation 3 systems will provide a further header that stay
# to tell us the version of the browser as well as the firmware. It
# seems like PlayStation systems are often spoofed because of the
# limited browser, and the limited javascript that is running on it.
SecRule REQUEST_HEADERS:User-Agent "playstation 3" \
        "id:436086,chain,phase:2,msg:'Fake PlayStation 3 browser: %{REQUEST_HEADERS.User-Agent}',deny,status:403"
SecRule &REQUEST_HEADERS:x-ps3-browser "@eq 0"

SecMarker FLAMEEYES_END_FAKE_BROWSERS_HEADERS
